{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO + ByteTrack Tracking\n",
    "\n",
    "Use YOLOv8's ByteTrack Tracker for champion icons trackingï¼š\n",
    "1. **Video file input**\n",
    "2. **Real-time Game Input**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Screen capture library (for real-time game)\n",
    "try:\n",
    "    import mss\n",
    "    MSS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Install mss: pip install mss\")\n",
    "    MSS_AVAILABLE = False\n",
    "\n",
    "print(\"Library imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: ./yolo/yolo_runs/minimap_detection/weights/best.pt\n",
      "Number of classes: 172\n",
      "Minimap region: Not set (will process full screen)\n"
     ]
    }
   ],
   "source": [
    "model_path = './yolo/yolo_runs/minimap_detection/weights/best.pt'\n",
    "conf_threshold = 0.25\n",
    "iou_threshold = 0.45\n",
    "\n",
    "minimap_region = None\n",
    "\n",
    "# check model file\n",
    "assert os.path.exists(model_path), f\"Model file not found: {model_path}\"\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)\n",
    "print(f\"Model loaded: {model_path}\")\n",
    "print(f\"Number of classes: {len(model.names)}\")\n",
    "print(f\"Minimap region: {minimap_region if minimap_region else 'Not set (will process full screen)'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimap region extraction tool defined\n"
     ]
    }
   ],
   "source": [
    "def extract_minimap_region(frame, region=None):\n",
    "    \"\"\"\n",
    "    Extract minimap region from frame\n",
    "    \n",
    "    Parameters:\n",
    "        frame: input frame (numpy array, BGR format)\n",
    "        region: minimap region (left, top, width, height), if None return original frame\n",
    "    \n",
    "    Returns:\n",
    "        extracted minimap region (numpy array)\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        return frame\n",
    "    \n",
    "    left, top, width, height = region\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # ensure region in image range\n",
    "    left = max(0, min(left, w))\n",
    "    top = max(0, min(top, h))\n",
    "    right = max(left, min(left + width, w))\n",
    "    bottom = max(top, min(top + height, h))\n",
    "    \n",
    "    minimap = frame[top:bottom, left:right]\n",
    "    return minimap\n",
    "\n",
    "def get_minimap_region_interactive(video_path=None, frame_index=0):\n",
    "    \"\"\"\n",
    "    Interactive tool: help user determine minimap region coordinates\n",
    "    \n",
    "    Parameters:\n",
    "        video_path: video file path\n",
    "        frame_index: video frame index\n",
    "    \n",
    "    Returns:\n",
    "        (left, top, width, height) or None\n",
    "    \"\"\"\n",
    "    if video_path:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        if not ret:\n",
    "            print(\"cannot read video frame\")\n",
    "            return None\n",
    "    else:\n",
    "        if not MSS_AVAILABLE:\n",
    "            print(\"need mss library to capture screen\")\n",
    "            return None\n",
    "        import mss\n",
    "        with mss.mss() as sct:\n",
    "            monitor = sct.monitors[1]\n",
    "            screenshot = sct.grab(monitor)\n",
    "            frame = np.array(screenshot)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    print(\"Please drag the mouse to select the minimap region, press 'Enter' to confirm, press 'Esc' to cancel\")\n",
    "    \n",
    "    # use mouse to select region\n",
    "    drawing = False\n",
    "    ix, iy = -1, -1\n",
    "    fx, fy = -1, -1\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        nonlocal drawing, ix, iy, fx, fy, frame_copy\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True\n",
    "            ix, iy = x, y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if drawing:\n",
    "                frame_copy = frame.copy()\n",
    "                cv2.rectangle(frame_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            drawing = False\n",
    "            fx, fy = x, y\n",
    "            frame_copy = frame.copy()\n",
    "            cv2.rectangle(frame_copy, (ix, iy), (fx, fy), (0, 255, 0), 2)\n",
    "    \n",
    "    frame_copy = frame.copy()\n",
    "    cv2.namedWindow('Select Minimap Region')\n",
    "    cv2.setMouseCallback('Select Minimap Region', mouse_callback)\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow('Select Minimap Region', frame_copy)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 13:  # Enter\n",
    "            if ix != -1 and fx != -1:\n",
    "                left = min(ix, fx)\n",
    "                top = min(iy, fy)\n",
    "                width = abs(fx - ix)\n",
    "                height = abs(fy - iy)\n",
    "                cv2.destroyAllWindows()\n",
    "                print(f\"Selected minimap region: ({left}, {top}, {width}, {height})\")\n",
    "                return (left, top, width, height)\n",
    "        elif key == 27:  # Esc\n",
    "            cv2.destroyAllWindows()\n",
    "            return None\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "\n",
    "print(\"Minimap region extraction tool defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics package path: c:\\Users\\82530\\anaconda3\\envs\\env\\Lib\\site-packages\\ultralytics\n",
      "Tracker config directory: c:\\Users\\82530\\anaconda3\\envs\\env\\Lib\\site-packages\\ultralytics\\cfg\\trackers\n",
      "\n",
      "Found config file: c:\\Users\\82530\\anaconda3\\envs\\env\\Lib\\site-packages\\ultralytics\\cfg\\trackers\\bytetrack.yaml\n",
      "\n",
      "=== ByteTrack config content ===\n",
      "# Ultralytics YOLO ðŸš€, AGPL-3.0 license\n",
      "# Default YOLO tracker settings for ByteTrack tracker https://github.com/ifzhang/ByteTrack\n",
      "\n",
      "tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
      "track_high_thresh: 0.5 # threshold for the first association\n",
      "track_low_thresh: 0.1 # threshold for the second association\n",
      "new_track_thresh: 0.6 # threshold for init new track if the detection does not match any tracks\n",
      "track_buffer: 30 # buffer to calculate the time when to remove tracks\n",
      "match_thresh: 0.8 # threshold for matching tracks\n",
      "fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
      "# min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)\n",
      "\n",
      "\n",
      "=== Config dictionary format ===\n",
      "{\n",
      "  \"tracker_type\": \"bytetrack\",\n",
      "  \"track_high_thresh\": 0.5,\n",
      "  \"track_low_thresh\": 0.1,\n",
      "  \"new_track_thresh\": 0.6,\n",
      "  \"track_buffer\": 30,\n",
      "  \"match_thresh\": 0.8,\n",
      "  \"fuse_score\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check ByteTrack config file\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# find by ultralytics package path\n",
    "try:\n",
    "    import ultralytics\n",
    "    ultralytics_path = Path(ultralytics.__file__).parent\n",
    "    tracker_dir = ultralytics_path / \"cfg\" / \"trackers\"\n",
    "    \n",
    "    print(f\"Ultralytics package path: {ultralytics_path}\")\n",
    "    print(f\"Tracker config directory: {tracker_dir}\")\n",
    "    \n",
    "    # find bytetrack.yaml\n",
    "    bytetrack_file = tracker_dir / \"bytetrack.yaml\"\n",
    "    if bytetrack_file.exists():\n",
    "        print(f\"\\nFound config file: {bytetrack_file}\")\n",
    "        print(\"\\n=== ByteTrack config content ===\")\n",
    "        with open(bytetrack_file, 'r', encoding='utf-8') as f:\n",
    "            config_content = f.read()\n",
    "            print(config_content)\n",
    "            \n",
    "        # parse to dictionary format\n",
    "        print(\"\\n=== Config dictionary format ===\")\n",
    "        with open(bytetrack_file, 'r', encoding='utf-8') as f:\n",
    "            config_dict = yaml.safe_load(f)\n",
    "            import json\n",
    "            print(json.dumps(config_dict, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(f\"File not found: {bytetrack_file}\")\n",
    "        # list all available tracker config files\n",
    "        if tracker_dir.exists():\n",
    "            print(f\"\\nAvailable tracker config files:\")\n",
    "            for f in tracker_dir.glob(\"*.yaml\"):\n",
    "                print(f\"  - {f.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom tracker config created: ./bytetrack_custom.yaml\n"
     ]
    }
   ],
   "source": [
    "# ByteTrack tracker custom config\n",
    "tracker_config = {\n",
    "    \"tracker_type\": \"bytetrack\",\n",
    "    \"track_high_thresh\": 0.45,\n",
    "    \"track_low_thresh\": 0.15,\n",
    "    \"new_track_thresh\": 0.6,\n",
    "    \"track_buffer\": 200,\n",
    "    \"match_thresh\": 0.65,\n",
    "    \"fuse_score\": True,\n",
    "    \"min_box_area\": 100\n",
    "}\n",
    "\n",
    "# create custom config file\n",
    "import yaml\n",
    "custom_tracker_path = \"./bytetrack_custom.yaml\"\n",
    "with open(custom_tracker_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(tracker_config, f, default_flow_style=False, allow_unicode=True)\n",
    "print(f\"Custom tracker config created: {custom_tracker_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Video Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_video(video_path, output_path=None, show_preview=True, save_output=True, minimap_region=None):\n",
    "    \"\"\"\n",
    "    Track video file (automatically extract minimap region)\n",
    "    \n",
    "    Parameters:\n",
    "        video_path: input video path\n",
    "        output_path: output video path (if None, auto generate)\n",
    "        show_preview: whether to show real-time preview\n",
    "        save_output: whether to save output video\n",
    "        minimap_region: minimap region (left, top, width, height), if None use global config or process full screen\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: video file not found: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # use global config or pass parameter\n",
    "    if minimap_region is None:\n",
    "        minimap_region = globals().get('minimap_region', None)\n",
    "    \n",
    "    if minimap_region is None:\n",
    "        print(\"Warning: Minimap region not specified, will process the whole video (recommended to specify minimap region for better performance)\")\n",
    "    \n",
    "    # auto generate output path\n",
    "    if output_path is None:\n",
    "        video_dir = os.path.dirname(video_path)\n",
    "        video_name = Path(video_path).stem\n",
    "        output_path = os.path.join(video_dir, f\"{video_name}_tracked.mp4\")\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"Minimap region: {minimap_region if minimap_region else 'Full screen'}\")\n",
    "    print(f\"Output path: {output_path}\")\n",
    "    \n",
    "    # if minimap region is specified, process frame by frame\n",
    "    if minimap_region is not None:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # get minimap size\n",
    "        left, top, w, h = minimap_region\n",
    "        minimap_w, minimap_h = w, h\n",
    "        \n",
    "        # create output video writer\n",
    "        if save_output:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (minimap_w, minimap_h))\n",
    "        \n",
    "        print(f\"Video info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "        print(f\"Minimap size: {minimap_w}x{minimap_h}\")\n",
    "        \n",
    "        frame_count = 0\n",
    "        all_results = []\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # extract minimap region\n",
    "            minimap_frame = extract_minimap_region(frame, minimap_region)\n",
    "            \n",
    "            # run tracking\n",
    "            results = model.track(\n",
    "                source=minimap_frame,\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                tracker=\"bytetrack.yaml\",\n",
    "                verbose=False,\n",
    "                augment=True\n",
    "            )\n",
    "            \n",
    "            all_results.append(results[0])\n",
    "            \n",
    "            # draw results\n",
    "            annotated_frame = results[0].plot()\n",
    "            \n",
    "            if save_output:\n",
    "                out.write(annotated_frame)\n",
    "            \n",
    "            if show_preview:\n",
    "                cv2.imshow('Tracking', annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"Processing: {frame_count}/{total_frames} ({100*frame_count/total_frames:.1f}%)\")\n",
    "        \n",
    "        cap.release()\n",
    "        if save_output:\n",
    "            out.release()\n",
    "        if show_preview:\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        print(f\"Tracking Output saved to: {output_path}\")\n",
    "        return all_results\n",
    "    else:\n",
    "        # if minimap region is not specified, process the whole video directly\n",
    "        results = model.track(\n",
    "            source=video_path,\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            tracker=\"bytetrack.yaml\",\n",
    "            save=save_output,\n",
    "            project='tracking_outputs',\n",
    "            name='video_tracking',\n",
    "            exist_ok=True,\n",
    "            show=show_preview,\n",
    "            verbose=True,\n",
    "            imgsz=640,\n",
    "            augment=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Tracking completed! Output saved to: {output_path}\")\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real-time Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def track_realtime_screen():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Tracking Data (API)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API functions defined\n"
     ]
    }
   ],
   "source": [
    "def get_tracking_data(results):\n",
    "    \"\"\"\n",
    "    Extract data from tracking results (for API)\n",
    "    \n",
    "    Parameters:\n",
    "        results: YOLO track() results\n",
    "    \n",
    "    Returns:\n",
    "        list: \n",
    "        [\n",
    "            {\n",
    "                'track_id': int,\n",
    "                'class_id': int,\n",
    "                'class_name': str,\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'confidence': float,\n",
    "                'center': [cx, cy]\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    tracking_data = []\n",
    "    \n",
    "    if results is None or len(results) == 0:\n",
    "        return tracking_data\n",
    "    \n",
    "    res = results[0]\n",
    "    \n",
    "    if len(res.boxes) == 0:\n",
    "        return tracking_data\n",
    "    \n",
    "    # get tracking ID\n",
    "    track_ids = res.boxes.id\n",
    "    if track_ids is None:\n",
    "        # if no tracking ID, use detection index as temporary ID\n",
    "        track_ids = np.arange(len(res.boxes))\n",
    "    \n",
    "    for i, (track_id, box, cls_id, conf) in enumerate(zip(\n",
    "        track_ids.cpu().numpy() if hasattr(track_ids, 'cpu') else track_ids,\n",
    "        res.boxes.xyxy.cpu().numpy(),\n",
    "        res.boxes.cls.cpu().numpy(),\n",
    "        res.boxes.conf.cpu().numpy()\n",
    "    )):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cls_id = int(cls_id)\n",
    "        class_name = res.names[cls_id] if hasattr(res, 'names') else str(cls_id)\n",
    "        \n",
    "        tracking_data.append({\n",
    "            'track_id': int(track_id),\n",
    "            'class_id': cls_id,\n",
    "            'class_name': class_name,\n",
    "            'bbox': [float(x1), float(y1), float(x2), float(y2)],\n",
    "            'confidence': float(conf),\n",
    "            'center': [float((x1 + x2) / 2), float((y1 + y2) / 2)]\n",
    "        })\n",
    "    \n",
    "    return tracking_data\n",
    "\n",
    "def process_frame_for_api(frame):\n",
    "    \"\"\"\n",
    "    Process single frame and return tracking data (for API)\n",
    "    \n",
    "    Parameters:\n",
    "        frame: numpy array (BGR format)\n",
    "    \n",
    "    Returns:\n",
    "        list: tracking data list\n",
    "    \"\"\"\n",
    "    results = model.track(\n",
    "        source=frame,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        tracker=\"bytetrack.yaml\",\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return get_tracking_data(results)\n",
    "\n",
    "def get_tracking_data_json(results, frame_number=None, timestamp=None, fps=None):\n",
    "    \"\"\"\n",
    "    generate JSON data with timestamp and frame number\n",
    "    \n",
    "    Parameters:\n",
    "        results: YOLO track() \n",
    "        frame_number: frame number (optional)\n",
    "        timestamp: timestamp, seconds (optional, if fps and frame_number are provided, it will be automatically calculated)\n",
    "        fps: video frame rate (optional, for calculating timestamp)\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON format dictionary, contains:\n",
    "        {\n",
    "            'timestamp': float,  # timestamp, seconds\n",
    "            'frame_number': int,  # frame number\n",
    "            'detections': [\n",
    "                {\n",
    "                    'class_id': int,\n",
    "                    'class_name': str,\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'confidence': float,\n",
    "                    'center': [cx, cy]\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    if isinstance(results, list) and len(results) > 0 and frame_number is not None:\n",
    "        frame_index = frame_number - 1\n",
    "        if 0 <= frame_index < len(results):\n",
    "            frame_results = [results[frame_index]]\n",
    "        else:\n",
    "            print(f\"Warning: frame_number {frame_number} out of range (total frames: {len(results)})\")\n",
    "            frame_results = [results[0]]  # use the first frame as default\n",
    "    elif isinstance(results, list) and len(results) > 0:\n",
    "        # if the results is a list but frame_number is not provided, use the first frame\n",
    "        frame_results = [results[0]]\n",
    "    else:\n",
    "        frame_results = results\n",
    "    \n",
    "    # calculate timestamp\n",
    "    if timestamp is None:\n",
    "        if fps is not None and frame_number is not None:\n",
    "            timestamp = frame_number / fps\n",
    "        else:\n",
    "            timestamp = time.time()  # use current timestamp\n",
    "    \n",
    "    # get tracking data\n",
    "    tracking_data = get_tracking_data(frame_results)\n",
    "\n",
    "    \n",
    "    # build JSON format\n",
    "    json_data = {\n",
    "        'timestamp': float(timestamp),\n",
    "        'frame_number': int(frame_number) if frame_number is not None else None,\n",
    "        'detections': []\n",
    "    }\n",
    "    \n",
    "    # add information of each detection target\n",
    "    for track in tracking_data:\n",
    "        json_data['detections'].append({\n",
    "            'class_id': track['class_id'],\n",
    "            'class_name': track['class_name'],\n",
    "            'bbox': track['bbox'],\n",
    "            'confidence': track['confidence'],\n",
    "            'center': track['center']\n",
    "        })\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "print(\"API functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST\n",
    "\n",
    "### Step 0: Minimap Region Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please drag the mouse to select the minimap region, press 'Enter' to confirm, press 'Esc' to cancel\n",
      "Selected minimap region: (1640, 801, 267, 265)\n",
      "Minimap region: (1640, 801, 267, 265)\n"
     ]
    }
   ],
   "source": [
    "video_path = \"./test_videos/video01_clip_4000frames.mp4\"\n",
    "minimap_region = get_minimap_region_interactive(video_path=video_path, frame_index=0)\n",
    "if minimap_region:\n",
    "    print(f\"Minimap region: {minimap_region}\")\n",
    "    minimap_region = minimap_region "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Processing Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: ./test_videos/video01_clip_4000frames.mp4\n",
      "Minimap region: (1640, 801, 267, 265)\n",
      "Output path: ./test_videos\\video01_clip_4000frames_tracked.mp4\n",
      "Video info: 1920x1080, 60 FPS, 4000 frames\n",
      "Minimap size: 267x265\n",
      "Processing: 30/4000 (0.8%)\n",
      "Processing: 60/4000 (1.5%)\n",
      "Processing: 90/4000 (2.2%)\n",
      "Processing: 120/4000 (3.0%)\n",
      "Processing: 150/4000 (3.8%)\n",
      "Processing: 180/4000 (4.5%)\n",
      "Processing: 210/4000 (5.2%)\n",
      "Processing: 240/4000 (6.0%)\n",
      "Processing: 270/4000 (6.8%)\n",
      "Processing: 300/4000 (7.5%)\n",
      "Processing: 330/4000 (8.2%)\n",
      "Processing: 360/4000 (9.0%)\n",
      "Processing: 390/4000 (9.8%)\n",
      "Processing: 420/4000 (10.5%)\n",
      "Processing: 450/4000 (11.2%)\n",
      "Processing: 480/4000 (12.0%)\n",
      "Processing: 510/4000 (12.8%)\n",
      "Processing: 540/4000 (13.5%)\n",
      "Processing: 570/4000 (14.2%)\n",
      "Processing: 600/4000 (15.0%)\n",
      "Processing: 630/4000 (15.8%)\n",
      "Processing: 660/4000 (16.5%)\n",
      "Processing: 690/4000 (17.2%)\n",
      "Processing: 720/4000 (18.0%)\n",
      "Processing: 750/4000 (18.8%)\n",
      "Processing: 780/4000 (19.5%)\n",
      "Processing: 810/4000 (20.2%)\n",
      "Processing: 840/4000 (21.0%)\n",
      "Processing: 870/4000 (21.8%)\n",
      "Processing: 900/4000 (22.5%)\n",
      "Processing: 930/4000 (23.2%)\n",
      "Processing: 960/4000 (24.0%)\n",
      "Processing: 990/4000 (24.8%)\n",
      "Processing: 1020/4000 (25.5%)\n",
      "Processing: 1050/4000 (26.2%)\n",
      "Processing: 1080/4000 (27.0%)\n",
      "Processing: 1110/4000 (27.8%)\n",
      "Processing: 1140/4000 (28.5%)\n",
      "Processing: 1170/4000 (29.2%)\n",
      "Processing: 1200/4000 (30.0%)\n",
      "Processing: 1230/4000 (30.8%)\n",
      "Processing: 1260/4000 (31.5%)\n",
      "Processing: 1290/4000 (32.2%)\n",
      "Processing: 1320/4000 (33.0%)\n",
      "Processing: 1350/4000 (33.8%)\n",
      "Processing: 1380/4000 (34.5%)\n",
      "Processing: 1410/4000 (35.2%)\n",
      "Processing: 1440/4000 (36.0%)\n",
      "Processing: 1470/4000 (36.8%)\n",
      "Processing: 1500/4000 (37.5%)\n",
      "Processing: 1530/4000 (38.2%)\n",
      "Processing: 1560/4000 (39.0%)\n",
      "Processing: 1590/4000 (39.8%)\n",
      "Processing: 1620/4000 (40.5%)\n",
      "Processing: 1650/4000 (41.2%)\n",
      "Processing: 1680/4000 (42.0%)\n",
      "Processing: 1710/4000 (42.8%)\n",
      "Processing: 1740/4000 (43.5%)\n",
      "Processing: 1770/4000 (44.2%)\n",
      "Processing: 1800/4000 (45.0%)\n",
      "Processing: 1830/4000 (45.8%)\n",
      "Processing: 1860/4000 (46.5%)\n",
      "Processing: 1890/4000 (47.2%)\n",
      "Processing: 1920/4000 (48.0%)\n",
      "Processing: 1950/4000 (48.8%)\n",
      "Processing: 1980/4000 (49.5%)\n",
      "Processing: 2010/4000 (50.2%)\n",
      "Processing: 2040/4000 (51.0%)\n",
      "Processing: 2070/4000 (51.8%)\n",
      "Processing: 2100/4000 (52.5%)\n",
      "Processing: 2130/4000 (53.2%)\n",
      "Processing: 2160/4000 (54.0%)\n",
      "Processing: 2190/4000 (54.8%)\n",
      "Processing: 2220/4000 (55.5%)\n",
      "Processing: 2250/4000 (56.2%)\n",
      "Processing: 2280/4000 (57.0%)\n",
      "Processing: 2310/4000 (57.8%)\n",
      "Processing: 2340/4000 (58.5%)\n",
      "Processing: 2370/4000 (59.2%)\n",
      "Processing: 2400/4000 (60.0%)\n",
      "Processing: 2430/4000 (60.8%)\n",
      "Processing: 2460/4000 (61.5%)\n",
      "Processing: 2490/4000 (62.2%)\n",
      "Processing: 2520/4000 (63.0%)\n",
      "Processing: 2550/4000 (63.8%)\n",
      "Processing: 2580/4000 (64.5%)\n",
      "Processing: 2610/4000 (65.2%)\n",
      "Processing: 2640/4000 (66.0%)\n",
      "Processing: 2670/4000 (66.8%)\n",
      "Processing: 2700/4000 (67.5%)\n",
      "Processing: 2730/4000 (68.2%)\n",
      "Processing: 2760/4000 (69.0%)\n",
      "Processing: 2790/4000 (69.8%)\n",
      "Processing: 2820/4000 (70.5%)\n",
      "Processing: 2850/4000 (71.2%)\n",
      "Processing: 2880/4000 (72.0%)\n",
      "Processing: 2910/4000 (72.8%)\n",
      "Processing: 2940/4000 (73.5%)\n",
      "Processing: 2970/4000 (74.2%)\n",
      "Processing: 3000/4000 (75.0%)\n",
      "Processing: 3030/4000 (75.8%)\n",
      "Processing: 3060/4000 (76.5%)\n",
      "Processing: 3090/4000 (77.2%)\n",
      "Processing: 3120/4000 (78.0%)\n",
      "Processing: 3150/4000 (78.8%)\n",
      "Processing: 3180/4000 (79.5%)\n",
      "Processing: 3210/4000 (80.2%)\n",
      "Processing: 3240/4000 (81.0%)\n",
      "Processing: 3270/4000 (81.8%)\n",
      "Processing: 3300/4000 (82.5%)\n",
      "Processing: 3330/4000 (83.2%)\n",
      "Processing: 3360/4000 (84.0%)\n",
      "Processing: 3390/4000 (84.8%)\n",
      "Processing: 3420/4000 (85.5%)\n",
      "Processing: 3450/4000 (86.2%)\n",
      "Processing: 3480/4000 (87.0%)\n",
      "Processing: 3510/4000 (87.8%)\n",
      "Processing: 3540/4000 (88.5%)\n",
      "Processing: 3570/4000 (89.2%)\n",
      "Processing: 3600/4000 (90.0%)\n",
      "Processing: 3630/4000 (90.8%)\n",
      "Processing: 3660/4000 (91.5%)\n",
      "Processing: 3690/4000 (92.2%)\n",
      "Processing: 3720/4000 (93.0%)\n",
      "Processing: 3750/4000 (93.8%)\n",
      "Processing: 3780/4000 (94.5%)\n",
      "Processing: 3810/4000 (95.2%)\n",
      "Processing: 3840/4000 (96.0%)\n",
      "Processing: 3870/4000 (96.8%)\n",
      "Processing: 3900/4000 (97.5%)\n",
      "Processing: 3930/4000 (98.2%)\n",
      "Processing: 3960/4000 (99.0%)\n",
      "Processing: 3990/4000 (99.8%)\n",
      "Tracking Output saved to: ./test_videos\\video01_clip_4000frames_tracked.mp4\n",
      "First frame detected 0 tracking targets\n"
     ]
    }
   ],
   "source": [
    "video_path = \"./test_videos/video01_clip_4000frames.mp4\"  # replace with your video path\n",
    "# minimap_region = (1200, 600, 400, 400)  # minimap region (left, top, width, height)\n",
    "results = track_video(\n",
    "    video_path=video_path,\n",
    "    output_path=None,  # auto generate output path\n",
    "    show_preview=True,  # show real-time preview\n",
    "    save_output=True,  # save output video\n",
    "    minimap_region=minimap_region  # specify minimap region (recommended)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Get JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': 33.333333333333336, 'frame_number': 2000, 'detections': [{'class_id': 53, 'class_name': 'Jhin', 'bbox': [231.13299560546875, 203.41073608398438, 257.2855224609375, 230.72093200683594], 'confidence': 0.9581935405731201, 'center': [244.20925903320312, 217.06582641601562]}, {'class_id': 10, 'class_name': 'Ashe', 'bbox': [198.15374755859375, 181.00765991210938, 225.3982391357422, 208.10093688964844], 'confidence': 0.954704225063324, 'center': [211.7760009765625, 194.55429077148438]}, {'class_id': 111, 'class_name': 'Riven', 'bbox': [50.81669616699219, 45.971412658691406, 78.05683898925781, 72.90955352783203], 'confidence': 0.9384623169898987, 'center': [64.436767578125, 59.44048309326172]}, {'class_id': 0, 'class_name': 'Aatrox', 'bbox': [114.51884460449219, 75.92973327636719, 142.05706787109375, 103.0188217163086], 'confidence': 0.8760802745819092, 'center': [128.2879638671875, 89.47427368164062]}, {'class_id': 7, 'class_name': 'Anivia', 'bbox': [152.40902709960938, 109.20135498046875, 180.76473999023438, 136.56918334960938], 'confidence': 0.8106859922409058, 'center': [166.58688354492188, 122.88526916503906]}]}\n"
     ]
    }
   ],
   "source": [
    "json_data = get_tracking_data_json(results, frame_number=2000, fps=60)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
